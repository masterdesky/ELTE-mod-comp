{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a95aea7-3c78-4dc9-8a46-ac3ac0827db8",
   "metadata": {},
   "source": [
    "# Data science in Python I. - Problems in data science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c6ee0f-bd5b-4572-8b78-606359d1c2cd",
   "metadata": {},
   "source": [
    "## Glossary\n",
    "\n",
    "<p style=\"font-size:16px;\">\n",
    "Data science primarily deals with datasets (surprise-surprise). There are a number of fundamental terms this field of science is built upon. It is undeniably necessary to be familiar with them before venturing any further into this field. Below you find a short list of the most important terms. A short description is also attached to all of them.\n",
    "</p>\n",
    "\n",
    "<ul style=\"font-size:16px;\">\n",
    "<li><b>Dataset</b> (<i>hu: adathalmaz</i>): An ensemble of datapoints. Denoted by upper case <code>X</code> by convention. Datasets can be (and most of the time is) multidimensional, which means the <code>x</code> (lower case) datapoints consist of more, than one components. In this case, datapoints can be considered to be \"vectors\", or at least a list of continuous/discrete/non-numeric values. It is also a common convention that in a table, rows denote the individual datapoints, while columns denote the different dimensions/components of datapoints.</li>\n",
    "\n",
    "<li><b>Labels</b> (<i>hu: címke</i>): Some datasets are not solely consists of the datapoints themeselves, but corresponding <b>labels</b> too. In normal cicumstances, every <code>x</code> datapoint has a corresponding <code>y</code> value. The list of labels are denoted by lower case <code>y</code> by convention.</li>\n",
    "\n",
    "<li><b>Features</b> (<i>no hu translation</i>): Another name for the different dimensions of an <code>X</code> dataset. This is the term that is primarily used for dataset dimensions in data science. In practice, most of the \"features\" represent an actual, measurable quantity.</li>\n",
    "\n",
    "<li><b>Class</b> (<i>hu: osztály</i>): In classifications problems, labels are discrete, which represent that every datapoint can be \"classified\" into a specific subset of the dataset. The interpretation of subsets can be arbitrary. They could simply represent \"bins\" or \"intervals\", in which the labels are \"binned to\" by value. Or they could be more meaningful. Eg. if the datapoints are images, labels could represent, whether there is a dog or a cat on the image.</li>\n",
    "\n",
    "<li><b>Model</b> (<i>same in magyar with double 'L'</i>): A \"model\" in data science has obviously a very similar meaning as in other fields of science. It means to represent some underlying connection between datapoins or between datapoints and labels in a dataset. In the context of modern data science, \"model\" represent an arbitrary mathematical operator or sequence of operators, that maps the <code>X</code> dataset to corresponding <code>y</code> values.</li>\n",
    "\n",
    "<li><b>Training/Learning</b> (<i>hu: tanulás/tanítás</i>): This is just a fancy and generalized way of saying \"fitting data on a model\". In numerous cases \"fitting data\" is not just a simple curve fitting, but a much more complex process that is harder to interpret. Also most machine learning methods work in a way, where they're optimizing model parameters during an iterative process. This can be well described by the terms \"training\" and \"learning\". Models are essentially \"trained\" over iterations, as they're \"learning\" the underlying correlation in the dataset.</li>\n",
    "\n",
    "<li><b>Supervised vs. unsupervised learning</b> (<i>hu: felügyelt-/felügyelet nélküli tanítás/tanulás</i>): It means whether we're using data with or without labels. If labels are attached to a dataset during training/learning, we're speaking about <b>supervised learning</b>, while if no labels are attached to our dataset, we're speaking about <b>unsupervised learning</b>.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a505bf-1dd2-4ae2-9ea3-ad06651c4c10",
   "metadata": {},
   "source": [
    "# Types of problems\n",
    "\n",
    "Overwhelming majority of the problems in data science can be classified into 3 groups: regression, classification and clustering.\n",
    "\n",
    "<img width=\"700px\" src=\"./images/three-pillars.png\" style=\"display:block; margin:auto;\"/>\n",
    "<p style=\"text-align:center; font-size:24px;\">\n",
    "  <b>Fig. 1. The three pillars of data science</b>\n",
    "</p>\n",
    "<p style=\"text-align:center; font-size:12px;\">\n",
    "  <b>Source: <a href=\"https://www.researchgate.net/figure/The-three-pillars-of-learning-in-data-science-clustering-flat-or-hierarchical_fig1_314626729\">https://www.researchgate.net/figure/The-three-pillars-of-learning-in-data-science-clustering-flat-or-hierarchical_fig1_314626729</a></b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07af7da0-7018-4ad5-80f8-0d78184f9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn, tensorflow, torch, etc.\n",
    "#import torch\n",
    "#import tensorflow as tf\n",
    "\n",
    "from sklearn.datasets import make_regression, make_classification, \\\n",
    "                             make_blobs, make_moons, make_circles\n",
    "# ...\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize seaborn with custom settings\n",
    "# Facecolor values from S. Conradi @S_Conradi/@profConradi\n",
    "custom_settings = {\n",
    "    'figure.facecolor': '#f4f0e8',\n",
    "    'axes.facecolor': '#f4f0e8',\n",
    "    'axes.edgecolor': '0.7',\n",
    "    'axes.linewidth' : '2',\n",
    "    'grid.color': '0.7',\n",
    "    'grid.linestyle': 'none',\n",
    "    'grid.alpha': 0.6,\n",
    "}\n",
    "sns.set_theme(palette=sns.color_palette('deep', as_cmap=False),\n",
    "              rc=custom_settings)\n",
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc8a68-b5fb-43ce-809b-9304b30fbf66",
   "metadata": {},
   "source": [
    "## 1. Regression\n",
    "\n",
    "<p style=\"text-align:center; font-size:20px;\">\n",
    "  <b>Data and label -> Model -> Continuous value</b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d75fa8-69af-4e8f-9431-eb79778a7670",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15749d56-f3ed-42e9-8492-f0ad3fbd90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=10,\n",
    "    n_targets=1,\n",
    "    random_state=57\n",
    ")\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b43c53-5a3c-4ad9-9b24-04440fe86f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abe306c-71df-4ea3-8db2-3395de79c90b",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4327771d-5fb3-484c-8ca4-6914937e190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 5), dpi=120)\n",
    "\n",
    "ax.plot(y, color='indianred', lw=2)\n",
    "\n",
    "ax.set_title('$y_{\\\\text{values}}$',\n",
    "             fontsize=30, fontweight='bold')\n",
    "ax.set_xticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e7aa5c-4781-4dd6-a11d-5a1085327f8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data $\\times$ Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18feb50b-a2e3-456f-a7a9-b2a6f170b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr, nc = 2, 5\n",
    "fig, axes = plt.subplots(nr, nc, figsize=(nc*5, nr*5), dpi=120)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.scatter(X[i], y, color='indianred', alpha=0.6)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f'$X_{{{i+1}}}$', fontsize=30, fontweight='bold')\n",
    "    ax.set_ylabel('$y$', fontsize=30, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f913da-15cc-4a77-9009-a5a8bb1dd8d3",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a6879-2ed3-4078-a64b-528873845b57",
   "metadata": {},
   "source": [
    "## 2. Classification\n",
    "\n",
    "<p style=\"text-align:center; font-size:20px;\">\n",
    "  <b>Data and label -> Model -> Discrete value</b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d23e2-91c1-46a7-9939-5b15deace323",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=10,\n",
    "    n_redundant=0,\n",
    "    n_classes=3\n",
    ")\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db458744-5757-4cf3-b562-b8452aee407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c994ee9-5c1d-4bbb-9815-0dd9e1d33f6c",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a436ff33-5563-49fb-9e5c-f99b7bf48469",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ''\n",
    "for i in y: s += f'{i} '\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f241c-2b00-4c0c-ab45-1f5ae9d0ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24, 5))\n",
    "\n",
    "ax.barh(*np.unique(y, return_counts=True), height=0.7,\n",
    "        color=cm.tab10(np.unique(y)))\n",
    "\n",
    "ax.set_yticks(np.unique(y))\n",
    "ax.set_yticklabels(np.unique(y))\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f1dd1-80cf-48ef-863a-8281eeebb26b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data $\\times$ Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d936b22-90b6-460c-bc88-3bacbb0036fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr, nc = 2, 5\n",
    "fig, axes = plt.subplots(nr, nc, figsize=(nc*5, nr*5), dpi=120)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.scatter(X[i], y, color='indianred', alpha=0.6)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f'$X_{{{i+1}}}$', fontsize=30, fontweight='bold')\n",
    "    ax.set_ylabel('$y$', fontsize=30, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda427b-b9f1-4a5e-bb09-6e061e505d1d",
   "metadata": {},
   "source": [
    "## 3. Clustering\n",
    "\n",
    "<p style=\"text-align:center; font-size:20px;\">\n",
    "  <b>Only data -> Model -> Discrete value</b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049f0d88-df7f-4d1c-83e7-1509cc669b61",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1112f4-f711-4ede-a570-d4dc619d113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1500\n",
    "# Create a dummy dataset of blobs\n",
    "Xb, yb = make_blobs(\n",
    "    n_samples=N,    # Number of points in the dataset\n",
    "    n_features=2,   # Dimension of the dataset (Here it's a 2D dataset)\n",
    "    centers=3,      # Number of blobs to create\n",
    "    cluster_std=[1.0, 2.5, 0.5],\n",
    "    center_box=(-10, 10),\n",
    "    random_state=57\n",
    ")\n",
    "\n",
    "# Create a dummy dataset of circles\n",
    "Xc, yc = make_circles(\n",
    "    n_samples=N,    # Number of points in the dataset\n",
    "    noise=0.05,\n",
    "    factor=0.6,\n",
    "    random_state=57\n",
    ")\n",
    "\n",
    "# Create a dummy dataset of moons\n",
    "Xm, ym = make_moons(\n",
    "    n_samples=N,    # Number of points in the dataset\n",
    "    noise=0.05,\n",
    "    random_state=57\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98872a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc8e58-4287-4861-9ae2-3e3f534e6bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize them\n",
    "nr, nc = 1, 3\n",
    "fig, axes = plt.subplots(nrows=nr, ncols=nc, figsize=(8*nc, 8*nr))\n",
    "\n",
    "Xi = (Xb, Xc, Xm)\n",
    "yi = (yb, yc, ym)\n",
    "for X, y, ax in zip(Xi, yi, axes.flat):\n",
    "\n",
    "    X = X - np.mean(X)\n",
    "    ax.scatter(*X.T, c=cm.viridis(y/np.max(y)), alpha=0.6)\n",
    "\n",
    "    lim = 1.1 * np.max(np.abs(X))\n",
    "    ax.set_xlim(-lim, lim)\n",
    "    ax.set_ylim(-lim, lim)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a562d81d-e078-4a32-acf6-57d1feb1e594",
   "metadata": {},
   "source": [
    "### Let's have a look at the first one..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3b96b5-8dc7-43c2-9e05-29ee45ce7fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy dataset of blobs\n",
    "Xb, yb = make_blobs(\n",
    "    n_samples=1000,  # Number of points in the dataset\n",
    "    n_features=10,  # Dimension of the dataset (Here it's 100D)\n",
    "    centers=3,       # Number of blobs to create\n",
    "    cluster_std=1.5,\n",
    "    center_box=(-10, 10),\n",
    "    random_state=57\n",
    ")\n",
    "Xb = pd.DataFrame(Xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e53b107-3fec-4319-b2cb-da9283229f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a64b0f-26b7-44b5-b377-3072248fda52",
   "metadata": {},
   "source": [
    "### Labels\n",
    "\n",
    "We do not have this information however in case of clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876c3cc-59f2-4122-bc6e-4ff34aef78e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ''\n",
    "for i in yb: s += f'{i} '\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ce870c-0e95-4e8b-9616-f51f3f4da15d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data $\\times$ Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee33f3-c14c-4469-808b-07b791cd349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr, nc = 2, 5\n",
    "fig, axes = plt.subplots(nr, nc, figsize=(nc*5, nr*5), dpi=120)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.scatter(Xb[i], yb,\n",
    "               color='indianred', alpha=0.6)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(f'$X_{{{i+1}}}$', fontsize=30, fontweight='bold')\n",
    "    ax.set_ylabel('$y$', fontsize=30, fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d68648b-380d-4463-ba53-849beb0519a0",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a469b3ac-4055-439b-839e-2c6cdfebd848",
   "metadata": {},
   "source": [
    "### Image processing\n",
    "\n",
    "If we consider images as **datapoints** (**rows**) in a dataset, then pixels of images can be considered as individual *features* (*columns*) of this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbf9b01-2beb-458c-84ef-fc946eb8cc3b",
   "metadata": {},
   "source": [
    "#### Subaru Telescope images with spectro-Z data from SDSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a5f0a1-53ed-4697-b209-be69b6f3b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"260_z0.132621.png\"\n",
    "img = plt.imread(f'./data/{f}')[:,:,0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), facecolor='black')\n",
    "ax.axis('off')\n",
    "ax.imshow(img, cmap=\"Greys_r\")\n",
    "plt.show()\n",
    "print(f\"{img.shape = }\")\n",
    "print(f\"num of pixels = {img.size}\")\n",
    "print(f\"Redshift is z = {f.split('z')[-1].split('.png')[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725cabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36370709-9e22-48d0-bdc2-8921bf9d074b",
   "metadata": {},
   "source": [
    "#### Now let's imagine a whole dataset of images like this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55de5a4-baf3-471d-a6ae-787642db7740",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDIR = '/home/masterdesky/data/Subaru/'\n",
    "files = np.array([os.path.join(DDIR, f) for f in os.listdir(DDIR)])\n",
    "X = np.array([plt.imread(f)[:,:,0].flatten() for f in files])\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af08d6fd-a843-4028-9e41-f586a6d5df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d6bede-6ce6-47f7-b96f-c1270e86ff3a",
   "metadata": {},
   "source": [
    "### Mixed dataset\n",
    "\n",
    "Data of 891 Titanic passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d3f540-464f-4206-ae79-16b5bfb94179",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"http://patbaa.web.elte.hu/physdm/data/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6772f694-fa30-4016-96a4-e69be7ac8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb381f8-8cef-472c-9354-d517353588e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24, 24), facecolor='black')\n",
    "\n",
    "# Determine the image extent and axis limits for dear Mr. Matplotlib\n",
    "x_lim = (0, X.values.shape[0]-1)\n",
    "y_lim = [-0.5, X.values.shape[1]-0.5]\n",
    "\n",
    "ax.imshow(X.isna().values.T,\n",
    "          extent=(x_lim[0], x_lim[-1], y_lim[0], y_lim[-1]),\n",
    "          aspect=10, cmap=\"Greys\", interpolation='none')\n",
    "\n",
    "# Y-AXIS FORMATTING\n",
    "ax.set_yticks(range(X.columns.size))\n",
    "ax.set_yticklabels(X.columns[::-1], ha='right')\n",
    "ax.tick_params(axis='both', which='major',\n",
    "               labelsize=12, pad=10, colors='white')\n",
    "\n",
    "ax.grid(True, axis='y', ls='--', alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07529bc5-1d80-4bd2-a17f-0824dc1205b4",
   "metadata": {},
   "source": [
    "**This dataset needs some preprocessing!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f03d38e-9dc1-4c24-8784-95162b8cdf02",
   "metadata": {},
   "source": [
    "### A completely different type of problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba2180f-99de-4295-b1e4-3fae22be7020",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta = \"MAAHKGAEHHHKAAEHHEQAAKHHHAAAEHHEK\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e2a9c5-2eaf-4664-a1aa-ab12dc7b4d16",
   "metadata": {},
   "source": [
    "<img src=\"./images/alphafold.png\"/></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61f8ac4-e4bb-4e0b-9abc-fe76a79a6079",
   "metadata": {},
   "source": [
    "# How to approach and handle a problem in data science?\n",
    "\n",
    "Most of the problems should be approached and treated similarly by following these simple steps:\n",
    "- Step 1.: Preprocess the dataset for analysis\n",
    "- Step 2.: Find, tune and fit a model or models on the preprocessed dataset\n",
    "- Step 3.: Make predictions using the trained model and evaluate and interpret the results\n",
    "\n",
    "<img src=\"./images/pipeline-full.png\"/></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec391f0-5c21-4696-8e15-d118b8f9b1a8",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "A lot of beginner machine learning/data science guide for specific datasets will tell you to work with the data in a very specific way without actually telling you **why** should you do it **that** way? Why *scaling* the data is necessary? Why should you use *hot encoding*? What else can be done about missing data entries besides simply dropping them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdf3364-4433-43c0-bf63-d462d51da95b",
   "metadata": {},
   "source": [
    "## 1.0. Every preprocessing starts with data exploration\n",
    "\n",
    "### Why? Because looking at the data could be extremely insightful...\n",
    "\n",
    "See this example at https://en.wikipedia.org/wiki/Anscombe's_quartet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7468639c-9d53-43d1-9084-036d19407352",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('./data/Anscombe_quartet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e987ee-3b85-4507-869f-34b7b99bdce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr, nc = 1, 4\n",
    "fig, axes = plt.subplots(nr, nc, figsize=(5*nc, 5*nr), dpi=120)\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "sc = 15\n",
    "Xs = [X['x123'], X['x123'], X['x123'], X['x4']]\n",
    "ys = [X['y1'], X['y2'], X['y3'], X['y4']]\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.scatter(Xs[i], ys[i], s=sc**2)\n",
    "    xi = np.linspace(-10, 25)\n",
    "    yi = 1/2 * xi + 3.0\n",
    "    ax.plot(xi, yi, color='tab:red', lw=5, alpha=0.7)\n",
    "    ax.set_xlim(0.8 * np.min(Xs), 1.1 * np.max(Xs))\n",
    "    ax.set_ylim(0.8 * np.min(ys), 1.1 * np.max(ys))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f68091-49ce-462d-bd0a-6ab8bee57ef9",
   "metadata": {},
   "source": [
    "#### 1.0.1. Looking at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f82ce6-9aa5-4510-a724-b62ada759b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"http://patbaa.web.elte.hu/physdm/data/titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff8f8c2-0d63-4dd6-8bc6-96c5be69efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5714289-3846-48b1-8730-a0d8d866161d",
   "metadata": {},
   "source": [
    "### 1.0.2. Exploring missing datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e2c48-978a-470f-b9aa-22ca011eaa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e4e2b0-5514-4c7f-ac7d-b92888b95729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24, 24), facecolor='black')\n",
    "\n",
    "# Determine the image extent and axis limits for dear Mr. Matplotlib\n",
    "x_lim = (0, X.values.shape[0]-1)\n",
    "y_lim = [-0.5, X.values.shape[1]-0.5]\n",
    "\n",
    "ax.imshow(X.isna().values.T,\n",
    "          extent=(x_lim[0], x_lim[-1], y_lim[0], y_lim[-1]),\n",
    "          aspect=10, cmap=\"Greys\", interpolation='none')\n",
    "\n",
    "# Y-AXIS FORMATTING\n",
    "ax.set_yticks(range(X.columns.size))\n",
    "ax.set_yticklabels(X.columns[::-1], ha='right')\n",
    "ax.tick_params(axis='both', which='major',\n",
    "               labelsize=15, pad=10, colors='white')\n",
    "\n",
    "ax.grid(True, axis='y', ls='--', alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f993e9e6-90e7-400d-a4b1-5be8650c7737",
   "metadata": {},
   "source": [
    "### 1.0.3. Exploring datatypes in the dataset\n",
    "\n",
    "Object? Int? Float? Other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1aef5f-2c44-429b-9c66-4e353a5ff289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The `dtypes` variable of a pandas DataFrame object stores the datatypes\n",
    "# of the columns in a specific DataFrame object\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f66b9-322d-494b-9c9a-f61ec4617786",
   "metadata": {},
   "source": [
    "### 1.0.4. Exploring distribution of feature values\n",
    "\n",
    "Explore a randomly generated classification dataset with 2 distinct classes and 8 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739afc48-72d6-4486-89f1-d0dbd72fff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=200,\n",
    "    n_features=8,\n",
    "    n_informative=4,\n",
    "    n_redundant=2,\n",
    "    n_repeated=0,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=2,\n",
    "    random_state=0,\n",
    ")\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb6591-2bf1-4c1d-a5c9-0e26ecb50f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f403bac3-0139-43b9-9b27-4b5b3d463146",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc, nr = 4, 2\n",
    "fig, axes = plt.subplots(nr, nc, figsize=(6*nc, 5*nr))\n",
    "\n",
    "mask = np.bool_(y)\n",
    "data = [X[mask], X[~mask]]\n",
    "cmap = [cm.Reds, cm.Blues]\n",
    "labl = ['Class 0', 'Class 1']\n",
    "for d, c, l in zip(data, cmap, labl):\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.grid(True, ls='--', alpha=0.6)\n",
    "\n",
    "        # Convention for plotting numpy.histogram results\n",
    "        hist, bins = np.histogram(d.values[:, i], bins=20, density=True)\n",
    "        width = 0.8 * (bins[1] - bins[0])\n",
    "        center = (bins[:-1] + bins[1:]) / 2\n",
    "        ax.bar(center, hist, width=width, label=l,\n",
    "               color=c(0.6), alpha=0.6)\n",
    "\n",
    "        ax.set_title(f\"Feature {i}\", fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='upper left', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbec388-e571-4364-af79-9d50416fc1b5",
   "metadata": {},
   "source": [
    "### 1.0.5. Exploring the correlation of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e027278-6b7c-430c-b152-318f24970187",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=100,    # Number of points in the data set\n",
    "    n_features=6,     # Number of features in the data set\n",
    "    n_informative=4,\n",
    "    n_redundant=2,\n",
    "    n_repeated=0,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=2,\n",
    "    random_state=0,\n",
    ")\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca0998e-ca46-4ffb-823c-ed7e5feab786",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c81a69-e22e-40f8-ba33-bee7c1a49abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    X,\n",
    "    kind='scatter',\n",
    "    diag_kind='kde'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ceadc8-ce6b-4c32-ab79-b2ba3d50c6d3",
   "metadata": {},
   "source": [
    "## 1.1. Handling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6852d2a8-c3da-404d-bd87-5b877c144b12",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1.1. Deleting rows or columns with too much NaN values\n",
    "\n",
    "- Rows with too much missing values cannot be filled up in a meaningful way\n",
    "- It's better to simply drop rows or columns with too many missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac29c963-150d-4e1a-b27c-98bade002c7d",
   "metadata": {},
   "source": [
    "### 1.1.2. Filling empty entries with values\n",
    "\n",
    "- Filling NaN entries with mean of existing values\n",
    "- Filling NaN entries with values sampled from the distribution of existing ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd23a58-ea79-42e2-8149-c8adcbbed833",
   "metadata": {},
   "source": [
    "## 1.2. Handling non-numeric data\n",
    "\n",
    "- Label encoding and one-hot encoding\n",
    "- Do nothing with them in case of numerous tree ensemble methods (eg. TabNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12093054-a88b-47cb-807b-f409782ffd26",
   "metadata": {},
   "source": [
    "## 1.3. Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73c0a3d-2bca-4fd5-b278-0a5a820a4b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be4a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.sdss import SDSS\n",
    "\n",
    "from astropy import coordinates as coords\n",
    "from astropy.visualization import ImageNormalize, ZScaleInterval\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, \\\n",
    "                                  LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71157e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f'''\n",
    "SELECT TOP 15\n",
    "    g.ra, g.dec, g.PetroRad_r, s.z\n",
    "FROM Galaxy g\n",
    "    JOIN\n",
    "        SpecObj s ON s.specObjID = g.specObjID\n",
    "WHERE\n",
    "    g.clean=1\n",
    "    AND g.PetroRad_r BETWEEN 20 AND 32\n",
    "    AND s.z BETWEEN 0.02 AND 0.05\n",
    "'''\n",
    "data = SDSS.query_sql(query, data_release=17).to_pandas()\n",
    "co = coords.SkyCoord(ra=data['ra'], dec=data['dec'], unit='deg', frame='icrs')\n",
    "imgs = SDSS.get_images(coordinates=co)\n",
    "X = pd.DataFrame(imgs[0][0].data.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016d8fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305c302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sdss_plate(imgs, index=0):\n",
    "    data = imgs[index][0].data\n",
    "    norm = ImageNormalize(data, interval=ZScaleInterval())\n",
    "    return data, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f409e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, norm = load_sdss_plate(imgs, index=0)\n",
    "\n",
    "nr, nc = 1, 2\n",
    "fig, axes = plt.subplots(nr, nc, figsize=(nc*10, nr*10))\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.025,\n",
    "                    left=0.05, right=0.95, bottom=0.05, top=0.95)\n",
    "ax = axes[0]\n",
    "ax.axis(False)\n",
    "ax.imshow(img, origin='lower', cmap='gray')\n",
    "ax.text(0.025, 0.975, 'Raw Image', color='white', fontweight='bold',\n",
    "        fontsize=30, ha='left', va='top', transform=ax.transAxes)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.axis(False)\n",
    "ax.imshow(img, origin='lower', cmap='gray', norm=norm)\n",
    "ax.text(0.025, 0.975, 'Normalized Image', color='white', fontweight='bold',\n",
    "        fontsize=30, ha='left', va='top', transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023eb3d0-b6b3-4163-b3d6-54c443b3b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('/home/masterdesky/data/CAMELS/2D_maps/data/Maps_Mtot_Nbody_IllustrisTNG_CV_z=0.00.npy')\n",
    "X = X.reshape((-1, 256**2))\n",
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eea8691-f0b3-43c0-a20b-6a22c38a0b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24, 5), dpi=120)\n",
    "ax.grid(True, ls='--', alpha=0.6)\n",
    "\n",
    "ax.plot(X.iloc[0])\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.tick_params(axis='y', labelsize=30)\n",
    "ax.yaxis.get_offset_text().set_fontsize(30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8d9c31-6d7f-4299-87a2-fd661f84ecb3",
   "metadata": {},
   "source": [
    "### Machine learning algorithms don't like values all over the scale!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11d6114-47a1-4613-b734-45bed55d7416",
   "metadata": {},
   "source": [
    "#### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7af293d-d26e-44fa-ac24-461c67f36078",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = StandardScaler().fit_transform(X)\n",
    "Xs = pd.DataFrame(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229a1c7a-5868-448e-833a-90c416e583f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ed8bb8-1110-4bd1-b031-138ff98aed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24, 5), dpi=120)\n",
    "ax.grid(True, ls='--', alpha=0.6)\n",
    "\n",
    "ax.plot(Xs.iloc[0])\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.tick_params(axis='y', labelsize=30)\n",
    "ax.yaxis.get_offset_text().set_fontsize(30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4292fce0-9bde-4d28-9a51-af20d082c1a8",
   "metadata": {},
   "source": [
    "### But what is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5d320-af6c-4822-a52c-a8a7098934be",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr, nc = 1, 2\n",
    "fig, axes = plt.subplots(nr, nc, figsize=(nc*10, nr*10))\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.025,\n",
    "                    left=0.05, right=0.95, bottom=0.05, top=0.95)\n",
    "ax = axes[0]\n",
    "ax.axis(False)\n",
    "ax.imshow(X.values, origin='lower', cmap='gray')\n",
    "ax.text(0.025, 0.975, 'Raw Image', color='white', fontweight='bold',\n",
    "        fontsize=30, ha='left', va='top', transform=ax.transAxes)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.axis(False)\n",
    "ax.imshow(Xs.values, origin='lower', cmap='gray')\n",
    "ax.text(0.025, 0.975, 'Scaled Image', color='white', fontweight='bold',\n",
    "        fontsize=30, ha='left', va='top', transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a004ae0-a27d-43cb-84f9-aa65d4ddba55",
   "metadata": {},
   "source": [
    "#### Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f36f1-7009-4216-903e-e510c7dcf3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn = Normalizer().fit_transform(X)\n",
    "Xn = pd.DataFrame(Xn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b69318-1ecf-470a-af88-5b0f839f7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5c980d-3f42-4af2-9be1-d2691897be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(24, 5), dpi=120)\n",
    "ax.grid(True, ls='--', alpha=0.6)\n",
    "\n",
    "ax.plot(Xn.iloc[0])\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.tick_params(axis='y', labelsize=30)\n",
    "ax.yaxis.get_offset_text().set_fontsize(30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba32746-0402-4c6b-b7f0-5601e572baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr, nc = 1, 2\n",
    "fig, axes = plt.subplots(nr, nc, figsize=(nc*10, nr*10))\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.025,\n",
    "                    left=0.05, right=0.95, bottom=0.05, top=0.95)\n",
    "ax = axes[0]\n",
    "ax.axis(False)\n",
    "ax.imshow(X.values, origin='lower', cmap='gray')\n",
    "ax.text(0.025, 0.975, 'Raw Image', color='white', fontweight='bold',\n",
    "        fontsize=30, ha='left', va='top', transform=ax.transAxes)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.axis(False)\n",
    "ax.imshow(Xn.values, origin='lower', cmap='gray')\n",
    "ax.text(0.025, 0.975, 'Normalized Image', color='white', fontweight='bold',\n",
    "        fontsize=30, ha='left', va='top', transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9e1335",
   "metadata": {},
   "source": [
    "#### Comparison of different scaling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe7c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nr, nc = 1, 2\n",
    "fig, axes = plt.subplots(nr, nc, figsize=(nc*10, nr*10))\n",
    "fig.subplots_adjust(hspace=0.1, wspace=0.025,\n",
    "                    left=0.05, right=0.95, bottom=0.05, top=0.95)\n",
    "ax = axes[0]\n",
    "ax.axis(False)\n",
    "ax.imshow(Xs.values, origin='lower', cmap='gray')\n",
    "ax.text(0.025, 0.975, 'Scaled Image', color='white', fontweight='bold',\n",
    "        fontsize=30, ha='left', va='top', transform=ax.transAxes)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.axis(False)\n",
    "ax.imshow(Xn.values, origin='lower', cmap='gray')\n",
    "ax.text(0.025, 0.975, 'Normalized Image', color='white', fontweight='bold',\n",
    "        fontsize=30, ha='left', va='top', transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0feaed-1a09-4d85-b8f2-40e33b4a559f",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709efc94-c30e-48e2-8c3d-fcb771f1f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=10,    # Number of points in the data set\n",
    "    n_features=6,     # Number of features in the data set\n",
    "    n_informative=4,\n",
    "    n_redundant=2,\n",
    "    n_repeated=0,\n",
    "    n_classes=2,\n",
    "    n_clusters_per_class=2,\n",
    "    random_state=0,\n",
    ")\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "categories = ['Dog', 'Cat', 'Raccoon', 'Bear']\n",
    "feat = np.random.choice(categories, size=100, replace=True)\n",
    "X[5] = pd.Series(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180431c-c17f-4fc9-a5c3-62b400349599",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4debb64-8844-4317-833a-7a9edf93f669",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xenc = OneHotEncoder().fit_transform(X[5].values.reshape(-1, 1)).toarray()\n",
    "Xenc = pd.DataFrame(np.array(Xenc, dtype=int), columns=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055d92cd-14fb-4548-b987-0a3bf5297895",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdc928d-ca1a-466a-ae2e-82012d67a59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfull = pd.concat((X.drop(columns=[5]), Xenc), axis=1)\n",
    "Xfull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8798e652-7d34-4e01-813d-3fda9bc566e4",
   "metadata": {},
   "source": [
    "## 1.4. Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f5caab-41ec-47bb-8209-d75d755e0a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62813bda-46ec-4e03-be46-ac1feb339373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...in the next section..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
